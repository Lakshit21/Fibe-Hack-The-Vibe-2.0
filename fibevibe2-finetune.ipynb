{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9544337,"sourceType":"datasetVersion","datasetId":5814533}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:07:53.762571Z","iopub.execute_input":"2024-10-04T06:07:53.762902Z","iopub.status.idle":"2024-10-04T06:08:07.299767Z","shell.execute_reply.started":"2024-10-04T06:07:53.762866Z","shell.execute_reply":"2024-10-04T06:08:07.298758Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.0.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers datasets huggingface_hub torch","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:07.301848Z","iopub.execute_input":"2024-10-04T06:08:07.302201Z","iopub.status.idle":"2024-10-04T06:08:19.394742Z","shell.execute_reply.started":"2024-10-04T06:08:07.302161Z","shell.execute_reply":"2024-10-04T06:08:19.393770Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-04T18:44:55.427256Z","iopub.execute_input":"2024-10-04T18:44:55.427903Z","iopub.status.idle":"2024-10-04T18:44:55.444052Z","shell.execute_reply.started":"2024-10-04T18:44:55.427849Z","shell.execute_reply":"2024-10-04T18:44:55.442613Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/fibe-hack-to-vibe-2-0-iab-dataset/sample_submission.csv\n/kaggle/input/fibe-hack-to-vibe-2-0-iab-dataset/train.csv\n/kaggle/input/fibe-hack-to-vibe-2-0-iab-dataset/test.csv\n/kaggle/input/fibe-hack-to-vibe-2-0-iab-dataset/cats\n","output_type":"stream"}]},{"cell_type":"code","source":"## Common ML Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pickle\nimport json\nimport os\nimport random\nimport math\nimport dotenv","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:44:53.083050Z","iopub.execute_input":"2024-10-04T18:44:53.083410Z","iopub.status.idle":"2024-10-04T18:44:55.425213Z","shell.execute_reply.started":"2024-10-04T18:44:53.083351Z","shell.execute_reply":"2024-10-04T18:44:55.423417Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, Trainer, TrainingArguments\nimport datasets\nfrom datasets import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom huggingface_hub import HfApi, Repository, login","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:20.622682Z","iopub.execute_input":"2024-10-04T06:08:20.623108Z","iopub.status.idle":"2024-10-04T06:08:38.769861Z","shell.execute_reply.started":"2024-10-04T06:08:20.623075Z","shell.execute_reply":"2024-10-04T06:08:38.768504Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import evaluate","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:38.771623Z","iopub.execute_input":"2024-10-04T06:08:38.772765Z","iopub.status.idle":"2024-10-04T06:08:39.966106Z","shell.execute_reply.started":"2024-10-04T06:08:38.772717Z","shell.execute_reply":"2024-10-04T06:08:39.965161Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:39.967400Z","iopub.execute_input":"2024-10-04T06:08:39.967768Z","iopub.status.idle":"2024-10-04T06:08:39.972553Z","shell.execute_reply.started":"2024-10-04T06:08:39.967719Z","shell.execute_reply":"2024-10-04T06:08:39.971508Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"HF_TOKEN = \"<HF-Token>\"","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:39.973660Z","iopub.execute_input":"2024-10-04T06:08:39.973939Z","iopub.status.idle":"2024-10-04T06:08:39.981233Z","shell.execute_reply.started":"2024-10-04T06:08:39.973908Z","shell.execute_reply":"2024-10-04T06:08:39.980360Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"login(token=HF_TOKEN)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:39.982324Z","iopub.execute_input":"2024-10-04T06:08:39.982629Z","iopub.status.idle":"2024-10-04T06:08:40.122814Z","shell.execute_reply.started":"2024-10-04T06:08:39.982599Z","shell.execute_reply":"2024-10-04T06:08:40.121863Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:40.126011Z","iopub.execute_input":"2024-10-04T06:08:40.126288Z","iopub.status.idle":"2024-10-04T06:08:40.187267Z","shell.execute_reply.started":"2024-10-04T06:08:40.126258Z","shell.execute_reply":"2024-10-04T06:08:40.186153Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:08:40.188613Z","iopub.execute_input":"2024-10-04T06:08:40.188926Z","iopub.status.idle":"2024-10-04T06:08:40.198395Z","shell.execute_reply.started":"2024-10-04T06:08:40.188893Z","shell.execute_reply":"2024-10-04T06:08:40.197386Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"common_file_path = \"/kaggle/input/fibe-hack-to-vibe-2-0-iab-dataset/{_fn}\"","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:44:55.445683Z","iopub.execute_input":"2024-10-04T18:44:55.446441Z","iopub.status.idle":"2024-10-04T18:44:55.452452Z","shell.execute_reply.started":"2024-10-04T18:44:55.446361Z","shell.execute_reply":"2024-10-04T18:44:55.451015Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"raw_train = pd.read_csv(common_file_path.format(_fn=\"train.csv\"))\nraw_test = pd.read_csv(common_file_path.format(_fn=\"test.csv\"))\nraw_smplsub = pd.read_csv(common_file_path.format(_fn=\"sample_submission.csv\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:44:55.455574Z","iopub.execute_input":"2024-10-04T18:44:55.456225Z","iopub.status.idle":"2024-10-04T18:45:33.125141Z","shell.execute_reply.started":"2024-10-04T18:44:55.456170Z","shell.execute_reply":"2024-10-04T18:45:33.124132Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"raw_train.iloc[1]","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:48:16.553812Z","iopub.execute_input":"2024-10-04T18:48:16.555031Z","iopub.status.idle":"2024-10-04T18:48:16.563582Z","shell.execute_reply.started":"2024-10-04T18:48:16.554986Z","shell.execute_reply":"2024-10-04T18:48:16.562489Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Unnamed: 0                                                    1\ntext          the learning point open digital education. a r...\ntarget                                       academic interests\nWord Count                                                  147\nName: 1, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"raw_train.iloc[1]['text']","metadata":{"execution":{"iopub.status.busy":"2024-10-04T18:48:03.991130Z","iopub.execute_input":"2024-10-04T18:48:03.991588Z","iopub.status.idle":"2024-10-04T18:48:04.000440Z","shell.execute_reply.started":"2024-10-04T18:48:03.991545Z","shell.execute_reply":"2024-10-04T18:48:03.999329Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'the learning point open digital education. a repository of tutorials and visualizations to help students learn computer science, mathematics, physics and electrical engineering basics. visualizations are in the form of java applets and html5 visuals. graphical educational content for mathematics, science, computer science. cs topics covered : greedy algorithms, dynamic programming, linked lists, arrays, graphs, depth first search, breadth first search, dfs and bfs, circular linked lists, functional programming, programming interview questions, graphics and solid modelling toolsphysics : projectile motion, mechanics, electrostatics, electromagnetism, engineering mechanics, optical instruments, wave motion, applets and visualizations. mathematics: algebra, linear algebra, trigonometry, euclidean and analytic geometry, probability, game theory, operations research, calculus of single/multiple variable(s). electrical engineering : dc circuits, digital circuits. a listing of cbse and cisce schools, where students appear for cbse, isc, icse examinations. schools in mumbai, delhi, bangalore, hyderabad, kolkata, chennai. bangalore, pune, jaipur, lucknow, dehradun, gurgaon etc.'"},"metadata":{}}]},{"cell_type":"code","source":"with open(common_file_path.format(_fn=\"cats\"), \"rb\") as fp:\n    cats = pickle.load(fp)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:10.891794Z","iopub.execute_input":"2024-10-04T06:09:10.892107Z","iopub.status.idle":"2024-10-04T06:09:10.898161Z","shell.execute_reply.started":"2024-10-04T06:09:10.892074Z","shell.execute_reply":"2024-10-04T06:09:10.897227Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"cats","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:10.899329Z","iopub.execute_input":"2024-10-04T06:09:10.899642Z","iopub.status.idle":"2024-10-04T06:09:10.908223Z","shell.execute_reply.started":"2024-10-04T06:09:10.899609Z","shell.execute_reply":"2024-10-04T06:09:10.907236Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['academic interests',\n 'books and literature',\n 'healthy living',\n 'careers',\n 'news and politics',\n 'shopping',\n 'style and fashion',\n 'family and relationships',\n 'business and finance',\n 'automotives',\n 'pharmaceuticals, conditions, and symptoms',\n 'arts and culture',\n 'sports',\n 'pets',\n 'hobbies and interests',\n 'real estate',\n 'food and drinks',\n 'home and garden',\n 'video gaming',\n 'movies',\n 'travel',\n 'personal finance',\n 'technology and computing',\n 'music and audio',\n 'television',\n 'health']"},"metadata":{}}]},{"cell_type":"code","source":"cats_dict = {}\nfor i in range(len(cats)):\n    cats_dict[ cats[i] ] = i","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:10.909480Z","iopub.execute_input":"2024-10-04T06:09:10.909844Z","iopub.status.idle":"2024-10-04T06:09:10.915688Z","shell.execute_reply.started":"2024-10-04T06:09:10.909802Z","shell.execute_reply":"2024-10-04T06:09:10.914783Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"cats_dict","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:10.916712Z","iopub.execute_input":"2024-10-04T06:09:10.917056Z","iopub.status.idle":"2024-10-04T06:09:10.928389Z","shell.execute_reply.started":"2024-10-04T06:09:10.917018Z","shell.execute_reply":"2024-10-04T06:09:10.927482Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"{'academic interests': 0,\n 'books and literature': 1,\n 'healthy living': 2,\n 'careers': 3,\n 'news and politics': 4,\n 'shopping': 5,\n 'style and fashion': 6,\n 'family and relationships': 7,\n 'business and finance': 8,\n 'automotives': 9,\n 'pharmaceuticals, conditions, and symptoms': 10,\n 'arts and culture': 11,\n 'sports': 12,\n 'pets': 13,\n 'hobbies and interests': 14,\n 'real estate': 15,\n 'food and drinks': 16,\n 'home and garden': 17,\n 'video gaming': 18,\n 'movies': 19,\n 'travel': 20,\n 'personal finance': 21,\n 'technology and computing': 22,\n 'music and audio': 23,\n 'television': 24,\n 'health': 25}"},"metadata":{}}]},{"cell_type":"code","source":"raw_train['label'] = raw_train.target.apply(lambda x : cats_dict[x])","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:10.929836Z","iopub.execute_input":"2024-10-04T06:09:10.930164Z","iopub.status.idle":"2024-10-04T06:09:11.377675Z","shell.execute_reply.started":"2024-10-04T06:09:10.930133Z","shell.execute_reply":"2024-10-04T06:09:11.376756Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"raw_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:11.378951Z","iopub.execute_input":"2024-10-04T06:09:11.379281Z","iopub.status.idle":"2024-10-04T06:09:11.394199Z","shell.execute_reply.started":"2024-10-04T06:09:11.379247Z","shell.execute_reply":"2024-10-04T06:09:11.393266Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                               text  \\\n0           0  python courses python courses, python exercise...   \n1           1  the learning point open digital education. a r...   \n2           2  tech news, latest technology, mobiles, laptops...   \n3           3  the best it certification materials in usa | k...   \n4           4  bioland scientific, for your research needs bi...   \n\n               target  Word Count  label  \n0  academic interests         125      0  \n1  academic interests         147      0  \n2  academic interests         143      0  \n3  academic interests         364      0  \n4  academic interests         176      0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>text</th>\n      <th>target</th>\n      <th>Word Count</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>python courses python courses, python exercise...</td>\n      <td>academic interests</td>\n      <td>125</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>the learning point open digital education. a r...</td>\n      <td>academic interests</td>\n      <td>147</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>tech news, latest technology, mobiles, laptops...</td>\n      <td>academic interests</td>\n      <td>143</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>the best it certification materials in usa | k...</td>\n      <td>academic interests</td>\n      <td>364</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>bioland scientific, for your research needs bi...</td>\n      <td>academic interests</td>\n      <td>176</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X_main = list(raw_train[\"text\"].values)\ny_main = list(raw_train[\"label\"].values)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:11.395838Z","iopub.execute_input":"2024-10-04T06:09:11.396491Z","iopub.status.idle":"2024-10-04T06:09:11.513770Z","shell.execute_reply.started":"2024-10-04T06:09:11.396438Z","shell.execute_reply":"2024-10-04T06:09:11.512754Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train_texts, test_texts, train_labels, test_labels = train_test_split(\n    X_main, y_main, random_state=42, test_size=0.1, stratify=y_main\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:11.515253Z","iopub.execute_input":"2024-10-04T06:09:11.516254Z","iopub.status.idle":"2024-10-04T06:09:12.341031Z","shell.execute_reply.started":"2024-10-04T06:09:11.516206Z","shell.execute_reply":"2024-10-04T06:09:12.340250Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"class NewsDataset(torch.utils.data.Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __getitem__(self, idx):\n        # Tokenize the text when it's retrieved\n        encoding = self.tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_length,\n            return_tensors=\"pt\"\n        )\n        item = {key: val.squeeze(0) for key, val in encoding.items()}  # Squeeze to remove batch dim\n        item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:12.342169Z","iopub.execute_input":"2024-10-04T06:09:12.342472Z","iopub.status.idle":"2024-10-04T06:09:12.350147Z","shell.execute_reply.started":"2024-10-04T06:09:12.342439Z","shell.execute_reply":"2024-10-04T06:09:12.349142Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\", num_labels=26)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:12.351404Z","iopub.execute_input":"2024-10-04T06:09:12.351933Z","iopub.status.idle":"2024-10-04T06:09:13.593322Z","shell.execute_reply.started":"2024-10-04T06:09:12.351889Z","shell.execute_reply":"2024-10-04T06:09:13.592294Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d0f5eff414f44a9b945185ef953a7ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be1e4a9cc92d4c21a5bf6bcb5138a264"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e216b437115d469c9a22bd389e432aac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"138d28af29c64e19bc95cc4fc33c03d6"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataset = NewsDataset(train_texts, train_labels, tokenizer)\ntest_dataset = NewsDataset(test_texts, test_labels, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:13.594576Z","iopub.execute_input":"2024-10-04T06:09:13.594882Z","iopub.status.idle":"2024-10-04T06:09:13.600165Z","shell.execute_reply.started":"2024-10-04T06:09:13.594850Z","shell.execute_reply":"2024-10-04T06:09:13.599227Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')  # Multi-class metric\n    acc = accuracy_score(labels, preds)\n    return {\n        'accuracy': acc,\n        'f1': f1,\n        'precision': precision,\n        'recall': recall\n    }","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:09:13.601359Z","iopub.execute_input":"2024-10-04T06:09:13.601857Z","iopub.status.idle":"2024-10-04T06:09:13.610574Z","shell.execute_reply.started":"2024-10-04T06:09:13.601815Z","shell.execute_reply":"2024-10-04T06:09:13.609709Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Define batch size variable\nbatch_size = 32  # Change this to any value you want (32, 64, etc.)\n\ntraining_args = TrainingArguments(\n    output_dir=\"results\",  # output directory\n    overwrite_output_dir=True,\n    num_train_epochs=2,  # total number of training epochs\n    per_device_train_batch_size=batch_size,  # use the batch_size variable\n    per_device_eval_batch_size=batch_size,  # use the batch_size variable\n    warmup_steps=500,  # reduce warmup steps to speed up training\n    weight_decay=0.01,  # strength of weight decay\n    logging_dir=\"logs\",  # directory for storing logs\n    logging_steps=5000,  # log after every 500 steps\n    save_steps=5000,  # save checkpoint every 500 steps\n    learning_rate=1e-5,  # maintain learning rate\n    do_train=True,\n    do_eval=True,\n    seed=42,\n    gradient_accumulation_steps=1,  # no need for gradient accumulation with a large batch size\n    fp16=True,  # Enable mixed precision training for faster computations\n    push_to_hub=True,\n    hub_model_id=\"LakshitKava/Fibe_IAB_DB_v2\",\n    report_to=\"all\"  # Reports logs to both TensorBoard and Hub\n)\n\n# Loading the model with 26 output labels\nmodel = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=26)\n\ntrainer = Trainer(\n    model=model,  # the instantiated Transformers model to be trained\n    args=training_args,  # training arguments, defined above\n    compute_metrics=compute_metrics,\n    train_dataset=train_dataset,  # training dataset\n    eval_dataset=test_dataset,  # test dataset\n)\n\n# Optional: Use a DataLoader with more workers for faster data loading\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:12:32.766259Z","iopub.execute_input":"2024-10-04T06:12:32.766693Z","iopub.status.idle":"2024-10-04T06:12:33.201761Z","shell.execute_reply.started":"2024-10-04T06:12:32.766653Z","shell.execute_reply":"2024-10-04T06:12:33.200763Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n","output_type":"stream"}]},{"cell_type":"code","source":"model.device","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:12:35.968043Z","iopub.execute_input":"2024-10-04T06:12:35.969076Z","iopub.status.idle":"2024-10-04T06:12:35.975938Z","shell.execute_reply.started":"2024-10-04T06:12:35.969029Z","shell.execute_reply":"2024-10-04T06:12:35.974915Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}]},{"cell_type":"code","source":"%%time\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-04T06:12:37.537433Z","iopub.execute_input":"2024-10-04T06:12:37.538290Z","iopub.status.idle":"2024-10-04T16:41:25.026951Z","shell.execute_reply.started":"2024-10-04T06:12:37.538247Z","shell.execute_reply":"2024-10-04T16:41:25.026029Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='19618' max='19618' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [19618/19618 10:28:36, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>5000</td>\n      <td>1.013500</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>0.597300</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>0.526900</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"name":"stdout","text":"CPU times: user 10h 32min 58s, sys: 1min 31s, total: 10h 34min 30s\nWall time: 10h 28min 47s\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=19618, training_loss=0.6650083240279973, metrics={'train_runtime': 37718.6128, 'train_samples_per_second': 33.287, 'train_steps_per_second': 0.52, 'total_flos': 1.6639036304176742e+17, 'train_loss': 0.6650083240279973, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer","metadata":{"execution":{"iopub.status.busy":"2024-10-04T16:42:02.400340Z","iopub.execute_input":"2024-10-04T16:42:02.400745Z","iopub.status.idle":"2024-10-04T16:42:02.408174Z","shell.execute_reply.started":"2024-10-04T16:42:02.400709Z","shell.execute_reply":"2024-10-04T16:42:02.407178Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<transformers.trainer.Trainer at 0x7ff9556f0610>"},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"LakshitKava/Fibe_IAB_DB_v2_trainer\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T16:42:08.593390Z","iopub.execute_input":"2024-10-04T16:42:08.593793Z","iopub.status.idle":"2024-10-04T16:42:11.156317Z","shell.execute_reply.started":"2024-10-04T16:42:08.593756Z","shell.execute_reply":"2024-10-04T16:42:11.155458Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/LakshitKava/Fibe_IAB_DB_v2/commit/10223c498666e9bfcd39000a706fa37ac6fdbe8a', commit_message='LakshitKava/Fibe_IAB_DB_v2_trainer', commit_description='', oid='10223c498666e9bfcd39000a706fa37ac6fdbe8a', pr_url=None, repo_url=RepoUrl('https://huggingface.co/LakshitKava/Fibe_IAB_DB_v2', endpoint='https://huggingface.co', repo_type='model', repo_id='LakshitKava/Fibe_IAB_DB_v2'), pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(output_dir=\"mdl\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T16:43:12.590786Z","iopub.execute_input":"2024-10-04T16:43:12.591193Z","iopub.status.idle":"2024-10-04T16:43:15.327205Z","shell.execute_reply.started":"2024-10-04T16:43:12.591155Z","shell.execute_reply":"2024-10-04T16:43:15.326374Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ntrainer.evaluate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}